{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ch_IEz4HKdJv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13kfJcxdKdJ0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('olist_order_reviews_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "pL6wOOcuKdJ5",
    "outputId": "ecdf67e3-0723-456f-b464-af6bb3928021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      "review_id                  100000 non-null object\n",
      "order_id                   100000 non-null object\n",
      "review_score               100000 non-null int64\n",
      "review_comment_title       11715 non-null object\n",
      "review_comment_message     41753 non-null object\n",
      "review_creation_date       100000 non-null object\n",
      "review_answer_timestamp    100000 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "id": "yYHfrwWTKdKA",
    "outputId": "1d4d63a3-dd08-498d-a18f-a465e8cbd10c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15197aa66ff4d0650b5434f1b46cda19</td>\n",
       "      <td>b18dcdf73be66366873cd26c5724d1dc</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-13 00:00:00</td>\n",
       "      <td>2018-04-16 00:39:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07f9bee5d1b850860defd761afa7ff16</td>\n",
       "      <td>e48aa0d2dcec3a2e87348811bcfdf22b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-16 00:00:00</td>\n",
       "      <td>2017-07-18 19:30:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7c6400515c67679fbee952a7525281ef</td>\n",
       "      <td>c31a859e34e3adac22f376954e19b39d</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-14 00:00:00</td>\n",
       "      <td>2018-08-14 21:36:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a3f6f7f6f433de0aefbb97da197c554c</td>\n",
       "      <td>9c214ac970e84273583ab523dfafd09b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-17 00:00:00</td>\n",
       "      <td>2017-05-18 12:05:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>4</td>\n",
       "      <td>recomendo</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>2018-05-22 00:00:00</td>\n",
       "      <td>2018-05-23 16:45:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "5  15197aa66ff4d0650b5434f1b46cda19  b18dcdf73be66366873cd26c5724d1dc   \n",
       "6  07f9bee5d1b850860defd761afa7ff16  e48aa0d2dcec3a2e87348811bcfdf22b   \n",
       "7  7c6400515c67679fbee952a7525281ef  c31a859e34e3adac22f376954e19b39d   \n",
       "8  a3f6f7f6f433de0aefbb97da197c554c  9c214ac970e84273583ab523dfafd09b   \n",
       "9  8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "5             1                  NaN   \n",
       "6             5                  NaN   \n",
       "7             5                  NaN   \n",
       "8             5                  NaN   \n",
       "9             4            recomendo   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "5                                                NaN  2018-04-13 00:00:00   \n",
       "6                                                NaN  2017-07-16 00:00:00   \n",
       "7                                                NaN  2018-08-14 00:00:00   \n",
       "8                                                NaN  2017-05-17 00:00:00   \n",
       "9  aparelho eficiente. no site a marca do aparelh...  2018-05-22 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  \n",
       "5     2018-04-16 00:39:37  \n",
       "6     2017-07-18 19:30:34  \n",
       "7     2018-08-14 21:36:06  \n",
       "8     2017-05-18 12:05:37  \n",
       "9     2018-05-23 16:45:47  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "EY7gHqeuKdKG",
    "outputId": "f6948fa0-b382-4e70-8fcb-0d2ff2dfaa17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAHVCAYAAAD1rCFNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8AAAAOsReAAAgPX+H111Xl2BcVqVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa020ebfc50>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "ZkQR3MmdKdKK",
    "outputId": "d35d1e08-c802-49b3-cc0f-a072f4d9536a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.070890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.359663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_score\n",
       "count  100000.000000\n",
       "mean        4.070890\n",
       "std         1.359663\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "gXEDW8mjKdKV",
    "outputId": "ebeb259b-87d0-4d85-f289-50ed81d7e26f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      NaN\n",
       "1                                                      NaN\n",
       "2                                                      NaN\n",
       "3                    Recebi bem antes do prazo estipulado.\n",
       "4        Parabéns lojas lannister adorei comprar pela I...\n",
       "5                                                      NaN\n",
       "6                                                      NaN\n",
       "7                                                      NaN\n",
       "8                                                      NaN\n",
       "9        aparelho eficiente. no site a marca do aparelh...\n",
       "10                                                     NaN\n",
       "11                                                     NaN\n",
       "12         Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "13                                                     NaN\n",
       "14                                                     NaN\n",
       "15       Vendedor confiável, produto ok e entrega antes...\n",
       "16       GOSTARIA DE SABER O QUE HOUVE, SEMPRE RECEBI E...\n",
       "17                                                     NaN\n",
       "18                                                     NaN\n",
       "19                                                 Péssimo\n",
       "20                                                     NaN\n",
       "21                                                     NaN\n",
       "22                                            Loja nota 10\n",
       "23                                                     NaN\n",
       "24                   obrigado pela atençao amim dispensada\n",
       "25                                                     NaN\n",
       "26                                                     NaN\n",
       "27       A compra foi realizada facilmente.\\r\\nA entreg...\n",
       "28                          relógio muito bonito e barato.\n",
       "29                     Não gostei ! Comprei gato por lebre\n",
       "                               ...                        \n",
       "99970                                                  NaN\n",
       "99971    Ficamos muito satisfeitos com o produto, atend...\n",
       "99972    Bom dia \\r\\nDas 6 unidades compradas só recebi...\n",
       "99973                                                  NaN\n",
       "99974                                                  NaN\n",
       "99975    Foto muito diferente principalmente a graninha...\n",
       "99976                                                  NaN\n",
       "99977    Produto original,prazo de entrega rápido.Super...\n",
       "99978    Tive um problema na entrega em que o correio c...\n",
       "99979                                                  NaN\n",
       "99980    para este produto recebi de acordo com a compr...\n",
       "99981                                                  NaN\n",
       "99982                                                  NaN\n",
       "99983    Entregou dentro do prazo. O produto chegou em ...\n",
       "99984                                                  NaN\n",
       "99985                                                  NaN\n",
       "99986                                                  NaN\n",
       "99987                                                  NaN\n",
       "99988                                                  NaN\n",
       "99989                                                  NaN\n",
       "99990    O produto não foi enviado com NF, não existe v...\n",
       "99991                                                  NaN\n",
       "99992                                                  NaN\n",
       "99993                                                  NaN\n",
       "99994                                                  NaN\n",
       "99995                                                  NaN\n",
       "99996    Excelente mochila, entrega super rápida. Super...\n",
       "99997                                                  NaN\n",
       "99998    Solicitei a compra de uma capa de retrovisor c...\n",
       "99999    meu produto chegou e ja tenho que devolver, po...\n",
       "Name: review_comment_message, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_comment_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RnZ5-m0KdKa"
   },
   "outputs": [],
   "source": [
    "df1 = df[['review_score','review_comment_message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2054
    },
    "colab_type": "code",
    "id": "hPQXXbZCKdKe",
    "outputId": "883b23cd-a324-4c8c-ef25-ad140a898e1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>GOSTARIA DE SABER O QUE HOUVE, SEMPRE RECEBI E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>Péssimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>Loja nota 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>obrigado pela atençao amim dispensada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>A compra foi realizada facilmente.\\r\\nA entreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>relógio muito bonito e barato.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Não gostei ! Comprei gato por lebre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>Sempre compro pela Internet e a entrega ocorre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>Recebi exatamente o que esperava. As demais en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>Recomendo ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>muito boa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>Tô completamente apaixonada, loja super respon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Nada de chegar o meu pedido.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>Muito bom. muito cheiroso.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>otimo vendedor chegou ate antes do prazo , ado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>Processo de compra tranquilo e eficiente.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>Tomara q dure pois é de pelinho.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>recebi somente 1 controle Midea Split ESTILO.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>boa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>MT lindo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5</td>\n",
       "      <td>Ocorreu tudo como contratado sendo a entrega r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5</td>\n",
       "      <td>Amei achei lindo ,muito delicado adorei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4</td>\n",
       "      <td>Ótima loja para parceria: rápidíssima, produto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>Recomendo o vendedor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>O produto não chegou no prazo estipulado e cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>5</td>\n",
       "      <td>Espero receber esta semana, o que não seria tã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>5</td>\n",
       "      <td>Entregou no prazo certo, fiquei feliz com a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>5</td>\n",
       "      <td>Lindo relógio adorei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3</td>\n",
       "      <td>Comprei dois lustres pendentes, com a parceira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "      <td>Muito bom alta qualidade!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>5</td>\n",
       "      <td>Produto bonito, entregue bem valado e dentro d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5</td>\n",
       "      <td>Muito bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>Faltou 1 produto e os que recebi 1 veio quebrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5</td>\n",
       "      <td>chegou dentro do prazo e o produto é de excele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>aqui está descrevendo como entregue só que ate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5</td>\n",
       "      <td>Acho que rastreando o produto devia ser melhor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5</td>\n",
       "      <td>Ainda não tive a oportunidade de testar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3</td>\n",
       "      <td>Comecei a usar agora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>5</td>\n",
       "      <td>nada a declarar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>3</td>\n",
       "      <td>Comprar um produto correto na capa mas interno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3</td>\n",
       "      <td>entrega super rapida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3</td>\n",
       "      <td>Fiz um pedido de 4 garrafas de azeite.Chegaram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>5</td>\n",
       "      <td>O produto chegou muito rapido e de boa qualida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>Não posso! Estou aguardando a chegada do produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>Comprei dois produtos e recebi somente um. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>3</td>\n",
       "      <td>Não recomendaria esta loja nem pretendo voltar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>5</td>\n",
       "      <td>Recomendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>4</td>\n",
       "      <td>Atendeu minha expectativa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>5</td>\n",
       "      <td>Entrega antes do prazo. Produto muito prático ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2</td>\n",
       "      <td>decepcionado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>5</td>\n",
       "      <td>otimo produto só nao veio manual, mas sem prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>4</td>\n",
       "      <td>Uma das peças não encaixava, estava de diâmetr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>5</td>\n",
       "      <td>Excelente produto.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5</td>\n",
       "      <td>Tudo certo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>Demora na entrega, detestei o atendimento e NU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_score                             review_comment_message\n",
       "3               5              Recebi bem antes do prazo estipulado.\n",
       "4               5  Parabéns lojas lannister adorei comprar pela I...\n",
       "9               4  aparelho eficiente. no site a marca do aparelh...\n",
       "12              4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "15              5  Vendedor confiável, produto ok e entrega antes...\n",
       "16              2  GOSTARIA DE SABER O QUE HOUVE, SEMPRE RECEBI E...\n",
       "19              1                                            Péssimo\n",
       "22              5                                       Loja nota 10\n",
       "24              5              obrigado pela atençao amim dispensada\n",
       "27              5  A compra foi realizada facilmente.\\r\\nA entreg...\n",
       "28              5                     relógio muito bonito e barato.\n",
       "29              1                Não gostei ! Comprei gato por lebre\n",
       "32              1  Sempre compro pela Internet e a entrega ocorre...\n",
       "34              4  Recebi exatamente o que esperava. As demais en...\n",
       "36              5                                        Recomendo ,\n",
       "37              5                                         muito boa \n",
       "38              5  Tô completamente apaixonada, loja super respon...\n",
       "39              1                       Nada de chegar o meu pedido.\n",
       "43              5                         Muito bom. muito cheiroso.\n",
       "47              5  otimo vendedor chegou ate antes do prazo , ado...\n",
       "49              5          Processo de compra tranquilo e eficiente.\n",
       "50              5                   Tomara q dure pois é de pelinho.\n",
       "51              1  recebi somente 1 controle Midea Split ESTILO.\\...\n",
       "55              5                                                boa\n",
       "59              5                                           MT lindo\n",
       "61              5  Ocorreu tudo como contratado sendo a entrega r...\n",
       "62              5            Amei achei lindo ,muito delicado adorei\n",
       "64              4  Ótima loja para parceria: rápidíssima, produto...\n",
       "67              5                           Recomendo o vendedor... \n",
       "68              1  O produto não chegou no prazo estipulado e cau...\n",
       "..            ...                                                ...\n",
       "170             5  Espero receber esta semana, o que não seria tã...\n",
       "174             5  Entregou no prazo certo, fiquei feliz com a co...\n",
       "178             5                               Lindo relógio adorei\n",
       "180             3  Comprei dois lustres pendentes, com a parceira...\n",
       "185             5                          Muito bom alta qualidade!\n",
       "188             5  Produto bonito, entregue bem valado e dentro d...\n",
       "189             5                                          Muito bom\n",
       "190             1   Faltou 1 produto e os que recebi 1 veio quebrado\n",
       "191             5  chegou dentro do prazo e o produto é de excele...\n",
       "197             1  aqui está descrevendo como entregue só que ate...\n",
       "198             5  Acho que rastreando o produto devia ser melhor...\n",
       "199             5            Ainda não tive a oportunidade de testar\n",
       "201             3                              Comecei a usar agora \n",
       "204             5                                    nada a declarar\n",
       "207             3  Comprar um produto correto na capa mas interno...\n",
       "210             3                               entrega super rapida\n",
       "212             3  Fiz um pedido de 4 garrafas de azeite.Chegaram...\n",
       "213             5  O produto chegou muito rapido e de boa qualida...\n",
       "221             1  Não posso! Estou aguardando a chegada do produ...\n",
       "223             1  Comprei dois produtos e recebi somente um. Man...\n",
       "227             3  Não recomendaria esta loja nem pretendo voltar...\n",
       "228             5                                          Recomendo\n",
       "229             4                         Atendeu minha expectativa.\n",
       "230             5  Entrega antes do prazo. Produto muito prático ...\n",
       "231             2                                       decepcionado\n",
       "236             5  otimo produto só nao veio manual, mas sem prob...\n",
       "237             4  Uma das peças não encaixava, estava de diâmetr...\n",
       "238             5                                 Excelente produto.\n",
       "239             5                                         Tudo certo\n",
       "240             1  Demora na entrega, detestei o atendimento e NU...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(inplace=True)\n",
    "df1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CZiYLw3EmzBv",
    "outputId": "1dcd4d61-f77b-438f-a50d-f7a7ff0532e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1,\n",
       "       'Não posso! Estou aguardando a chegada do produto que comprei!Logo que isso aconteça, terei minha opinião formada!'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGWdD4oEKdKj"
   },
   "outputs": [],
   "source": [
    "labels , reviews = df1['review_score'].values,df1['review_comment_message'].apply(str.lower).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUgA01NUKdKu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70RKTqjXKdKz"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# get rid of punctuation\n",
    "reviews_split= []\n",
    "for review in reviews:\n",
    "    reviews_split.append(''.join([c for c in review if c not in punctuation]).replace('\\r\\n',' '))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split by new lines and spaces\n",
    "#reviews_split = all_text.split('\\n')\n",
    "all_text = ' '.join(reviews_split)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "Esu5uSAcKdK4",
    "outputId": "0fd0c882-f6f1-4d7f-fff3-a817280fe77e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recebi',\n",
       " 'bem',\n",
       " 'antes',\n",
       " 'do',\n",
       " 'prazo',\n",
       " 'estipulado',\n",
       " 'parabéns',\n",
       " 'lojas',\n",
       " 'lannister',\n",
       " 'adorei',\n",
       " 'comprar',\n",
       " 'pela',\n",
       " 'internet',\n",
       " 'seguro',\n",
       " 'e',\n",
       " 'prático',\n",
       " 'parabéns',\n",
       " 'a',\n",
       " 'todos',\n",
       " 'feliz',\n",
       " 'páscoa',\n",
       " 'aparelho',\n",
       " 'eficiente',\n",
       " 'no',\n",
       " 'site',\n",
       " 'a',\n",
       " 'marca',\n",
       " 'do',\n",
       " 'aparelho',\n",
       " 'esta']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "_oonyOCYKdK9",
    "outputId": "adafe487-5360-4a81-8bf5-3f3924878238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recebi bem antes do prazo estipulado',\n",
       " 'parabéns lojas lannister adorei comprar pela internet seguro e prático parabéns a todos feliz páscoa',\n",
       " 'aparelho eficiente no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nomeatualizar com a marca correta uma vez que é o mesmo aparelho',\n",
       " 'mas um pouco travandopelo valor ta boa ',\n",
       " 'vendedor confiável produto ok e entrega antes do prazo']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_split[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDUGPLCgKdLD"
   },
   "source": [
    "Encoding the words\n",
    "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our reviews into integers so they can be passed into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMfpTBefKdLF"
   },
   "outputs": [],
   "source": [
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "## use the dict to tokenize each review in reviews_split\n",
    "## store the tokenized reviews in reviews_ints\n",
    "reviews_ints = []\n",
    "for review in reviews_split:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nUfPcLxKKdLJ",
    "outputId": "7e48855e-a794-4502-fca5-276a2be2b63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  20190\n",
      "\n",
      "Tokenized review: \n",
      " [[15, 28, 13, 6, 9, 232]]\n"
     ]
    }
   ],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "print()\n",
    "\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', reviews_ints[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThurRk6LKdLO"
   },
   "outputs": [],
   "source": [
    "vocab_to_string = { ii: word for word, ii  in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6W3Y-gAKdXC"
   },
   "outputs": [],
   "source": [
    "encoded_labels = [1 if c>3 else 0 for c in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "Cps7W6VbLKZ-",
    "outputId": "bf58a373-d309-46d8-e1e7-b4816c21d595"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n12QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa01d8de5c0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(encoded_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WjGmRKSVKdLY",
    "outputId": "efa27df9-a325-42a1-8583-a62366e5667a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 132\n",
      "Maximum review length: 45\n"
     ]
    }
   ],
   "source": [
    "# outlier review stats\n",
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJO-2wOiKdLd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qHd_gA-PKdLh",
    "outputId": "ee6548d4-c171-49cb-b675-388428ce81e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  41753\n",
      "Number of reviews after removing outliers:  41621\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
    "\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "\n",
    "\n",
    "\n",
    "# remove 0-length reviews and their labels\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "\n",
    "\n",
    "print('Number of reviews after removing outliers: ', len(reviews_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0lA0QtXKdLm"
   },
   "outputs": [],
   "source": [
    "reviews_ints = reviews_ints[:41500]\n",
    "encoded_labels = encoded_labels[:41500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKTJt3XWKdLq"
   },
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "75PHo81YKdL0",
    "outputId": "5a6435b1-75ba-4227-ad78-4b2608fd6e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   80  156   64   94   75]\n",
      " [ 433  358   16   62    4  376    6  433  131 2429]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  186    5  174    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   4   37   17  498 2430    4   11   17  809   10]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  70  162  106  446    3    4   11 1942   13    6]\n",
      " [   0    0    0   15  228    1    8  168   51  326]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0   15  169   98  394]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  365   36   44]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  79   34   26 1782 8218   60   28 1053    3    5]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    2    7   14   16    9  232    3 2609  823]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 20\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGdsWCgZnttZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "eCzybuo7KdL5",
    "outputId": "439037bc-5ea8-419b-e272-0ff601d7b956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(33200, 20) \n",
      "Validation set: \t(4150, 20) \n",
      "Test set: \t\t(4150, 20)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NzIdXY7koNQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFuPV_8yKdL9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 25\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "__jtFX4JLTGj",
    "outputId": "0b8ce8e2-2cbb-4a83-c63d-fd07744b1a95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "id": "34PXDA_YKdME",
    "outputId": "e4d6f80b-0744-456e-848b-2a308f880004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([25, 20])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,     0,     0,    30,    31,  6720,  1803,     3,\n",
      "            48,   380,    31,  1470,     7,    83,   184,    43,     1,   135],\n",
      "        [    1,   454,     6,   201,   915,     1,   418,    24,   269,   210,\n",
      "             3,    46,   123,    27,    11,    41,   326,     6,     2,     3],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,    45,     2,    33,    21],\n",
      "        [   30,    12,  1180,    74,   752,    26,    11,  1243,   276,   535,\n",
      "            74,   495,   387,    24,  2801,    12,     4,   223,     3,     7],\n",
      "        [    0,     0,     0,     0,     7,   579,     1,     2,     3,     7,\n",
      "           579,     1,   514,   105,  1150,    24,   110,    26,   360,   294],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,    38,     2,   173,    14],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,    10,    19],\n",
      "        [    7,  3848,    50,  5897,     3,  5721,   129,   495,   175,     4,\n",
      "           179,    16,    62, 18354,    16,  1907,   135,     5,  5912,    23],\n",
      "        [  186,     5,   174,     1,     8,   289,    12,     1,    38, 18800,\n",
      "           598,    39,     5,   253,     8,    33,    30,     1,     2,     3],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,   564],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,    36,    97],\n",
      "        [  142,    31,   407,     3,    25,   181,    90,    26,    67,    20,\n",
      "          3605,  3020,  2976,  7569,     3,    25,    20,  3020,  2976, 17922],\n",
      "        [    0,    83,     8,   940,   205,    89,     3,    27,   153,    42,\n",
      "           334,    31,   368,   209,     8,    33,    30,   138,   116,  3324],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,   426],\n",
      "        [   21,   381,    51,   156,  2085,    23,   622,    68,    42,   162,\n",
      "           595,    34,   942,    68,   173,    83,   211,  2232,   211,  4014],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     2,    56,    22,    30,    96,     3,    25,   169,    20],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,    33,   109,     1,     2,     3,     4,    11,    17,  3171],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     2,    46,     3,    11,    47,    55],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,   109,     1,\n",
      "             2,    14,    47,    52,     6,     9,   228,   323,    85,    54],\n",
      "        [   30,     1,  4555,    68,    22,     1, 18937,   431,    24,   110,\n",
      "            12,     4,    34,     3,   235, 18938,     4,   179,   914,  2046],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     1,     2,     7,    17,    22],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,    53, 18453,    12,    53,    37,    11,    13,     6,    88],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     1,     2,    17,\n",
      "            22,    52,     6,     9,     3,    14,    24,    73,  7741,   103],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     2,     5,    59,    32],\n",
      "        [   51,   439, 18121, 18122,    23,   223,   235,     5,    80,   139,\n",
      "            50,    60,    28,    13,     6,     9,     3,    57,    40, 18123]])\n",
      "\n",
      "Sample label size:  torch.Size([25])\n",
      "Sample label: \n",
      " tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(valid_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdBVnV44KdMO"
   },
   "outputs": [],
   "source": [
    "def tradutor(review_int):\n",
    "    \n",
    "    texto=[vocab_to_string[c] if c != 0 else '' for c in review_int ]\n",
    "    \n",
    "    texto = ' '.join(texto)\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNNP2F5lKdMT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n75PARBJKdMX",
    "outputId": "8c712cf5-ba4e-401b-8fe8-3a0e725bfe12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5JtEDRfKdMd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOaj7nMdKdMf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_sizes = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_sizes, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZT4htsdTKdMk",
    "outputId": "d517c1bb-6276-4e41-cf2a-f0ef7bcab078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(20191, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 200\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMZp6bfJWGpJ"
   },
   "outputs": [],
   "source": [
    "if(train_on_gpu):\n",
    "    net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BJo9NU0KdMp"
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1615
    },
    "colab_type": "code",
    "id": "OG7kGWjSKdMs",
    "outputId": "7c538828-2165-4ef3-9b84-49922f95641a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/6... Step: 100... Loss: 0.468917... Val Loss: 0.400869\n",
      "Validation loss decreased (inf --> 0.400869).  Saving model ...\n",
      "Epoch: 1/6... Step: 200... Loss: 0.333964... Val Loss: 0.355875\n",
      "Validation loss decreased (0.400869 --> 0.355875).  Saving model ...\n",
      "Epoch: 1/6... Step: 300... Loss: 0.244975... Val Loss: 0.355585\n",
      "Validation loss decreased (0.355875 --> 0.355585).  Saving model ...\n",
      "Epoch: 1/6... Step: 400... Loss: 0.248727... Val Loss: 0.342316\n",
      "Validation loss decreased (0.355585 --> 0.342316).  Saving model ...\n",
      "Epoch: 1/6... Step: 500... Loss: 0.316493... Val Loss: 0.332701\n",
      "Validation loss decreased (0.342316 --> 0.332701).  Saving model ...\n",
      "Epoch: 1/6... Step: 600... Loss: 0.353145... Val Loss: 0.325526\n",
      "Validation loss decreased (0.332701 --> 0.325526).  Saving model ...\n",
      "Epoch: 1/6... Step: 700... Loss: 0.473479... Val Loss: 0.319695\n",
      "Validation loss decreased (0.325526 --> 0.319695).  Saving model ...\n",
      "Epoch: 1/6... Step: 800... Loss: 0.426661... Val Loss: 0.307513\n",
      "Validation loss decreased (0.319695 --> 0.307513).  Saving model ...\n",
      "Epoch: 1/6... Step: 900... Loss: 0.372691... Val Loss: 0.306077\n",
      "Validation loss decreased (0.307513 --> 0.306077).  Saving model ...\n",
      "Epoch: 1/6... Step: 1000... Loss: 0.315203... Val Loss: 0.306576\n",
      "Epoch: 1/6... Step: 1100... Loss: 0.266860... Val Loss: 0.298164\n",
      "Validation loss decreased (0.306077 --> 0.298164).  Saving model ...\n",
      "Epoch: 1/6... Step: 1200... Loss: 0.434117... Val Loss: 0.297918\n",
      "Validation loss decreased (0.298164 --> 0.297918).  Saving model ...\n",
      "Epoch: 1/6... Step: 1300... Loss: 0.283629... Val Loss: 0.291725\n",
      "Validation loss decreased (0.297918 --> 0.291725).  Saving model ...\n",
      "Epoch: 2/6... Step: 1400... Loss: 0.249222... Val Loss: 0.295930\n",
      "Epoch: 2/6... Step: 1500... Loss: 0.245148... Val Loss: 0.298682\n",
      "Epoch: 2/6... Step: 1600... Loss: 0.276324... Val Loss: 0.293404\n",
      "Epoch: 2/6... Step: 1700... Loss: 0.091779... Val Loss: 0.296831\n",
      "Epoch: 2/6... Step: 1800... Loss: 0.349066... Val Loss: 0.285415\n",
      "Validation loss decreased (0.291725 --> 0.285415).  Saving model ...\n",
      "Epoch: 2/6... Step: 1900... Loss: 0.212787... Val Loss: 0.286722\n",
      "Epoch: 2/6... Step: 2000... Loss: 0.306352... Val Loss: 0.289360\n",
      "Epoch: 2/6... Step: 2100... Loss: 0.318250... Val Loss: 0.288920\n",
      "Epoch: 2/6... Step: 2200... Loss: 0.457297... Val Loss: 0.286663\n",
      "Epoch: 2/6... Step: 2300... Loss: 0.332194... Val Loss: 0.286719\n",
      "Epoch: 2/6... Step: 2400... Loss: 0.105423... Val Loss: 0.284339\n",
      "Validation loss decreased (0.285415 --> 0.284339).  Saving model ...\n",
      "Epoch: 2/6... Step: 2500... Loss: 0.262572... Val Loss: 0.284798\n",
      "Epoch: 2/6... Step: 2600... Loss: 0.181366... Val Loss: 0.282634\n",
      "Validation loss decreased (0.284339 --> 0.282634).  Saving model ...\n",
      "Epoch: 3/6... Step: 2700... Loss: 0.162065... Val Loss: 0.298720\n",
      "Epoch: 3/6... Step: 2800... Loss: 0.294941... Val Loss: 0.299538\n",
      "Epoch: 3/6... Step: 2900... Loss: 0.204725... Val Loss: 0.295707\n",
      "Epoch: 3/6... Step: 3000... Loss: 0.291732... Val Loss: 0.295610\n",
      "Epoch: 3/6... Step: 3100... Loss: 0.084217... Val Loss: 0.297177\n",
      "Epoch: 3/6... Step: 3200... Loss: 0.577342... Val Loss: 0.296608\n",
      "Epoch: 3/6... Step: 3300... Loss: 0.147035... Val Loss: 0.298438\n",
      "Epoch: 3/6... Step: 3400... Loss: 0.270403... Val Loss: 0.293581\n",
      "Epoch: 3/6... Step: 3500... Loss: 0.129172... Val Loss: 0.292996\n",
      "Epoch: 3/6... Step: 3600... Loss: 0.143943... Val Loss: 0.308952\n",
      "Epoch: 3/6... Step: 3700... Loss: 0.079136... Val Loss: 0.290769\n",
      "Epoch: 3/6... Step: 3800... Loss: 0.078997... Val Loss: 0.298503\n",
      "Epoch: 3/6... Step: 3900... Loss: 0.191486... Val Loss: 0.297423\n",
      "Epoch: 4/6... Step: 4000... Loss: 0.241395... Val Loss: 0.304993\n",
      "Epoch: 4/6... Step: 4100... Loss: 0.246775... Val Loss: 0.328389\n",
      "Epoch: 4/6... Step: 4200... Loss: 0.233032... Val Loss: 0.317352\n",
      "Epoch: 4/6... Step: 4300... Loss: 0.123187... Val Loss: 0.315172\n",
      "Epoch: 4/6... Step: 4400... Loss: 0.218182... Val Loss: 0.328979\n",
      "Epoch: 4/6... Step: 4500... Loss: 0.331519... Val Loss: 0.329874\n",
      "Epoch: 4/6... Step: 4600... Loss: 0.313021... Val Loss: 0.336509\n",
      "Epoch: 4/6... Step: 4700... Loss: 0.230711... Val Loss: 0.319332\n",
      "Epoch: 4/6... Step: 4800... Loss: 0.025916... Val Loss: 0.323955\n",
      "Epoch: 4/6... Step: 4900... Loss: 0.031593... Val Loss: 0.341793\n",
      "Epoch: 4/6... Step: 5000... Loss: 0.228063... Val Loss: 0.329758\n",
      "Epoch: 4/6... Step: 5100... Loss: 0.069229... Val Loss: 0.329787\n",
      "Epoch: 4/6... Step: 5200... Loss: 0.086659... Val Loss: 0.332308\n",
      "Epoch: 4/6... Step: 5300... Loss: 0.316442... Val Loss: 0.345189\n",
      "Epoch: 5/6... Step: 5400... Loss: 0.013405... Val Loss: 0.379796\n",
      "Epoch: 5/6... Step: 5500... Loss: 0.203381... Val Loss: 0.392906\n",
      "Epoch: 5/6... Step: 5600... Loss: 0.198138... Val Loss: 0.382039\n",
      "Epoch: 5/6... Step: 5700... Loss: 0.105518... Val Loss: 0.392519\n",
      "Epoch: 5/6... Step: 5800... Loss: 0.137162... Val Loss: 0.404873\n",
      "Epoch: 5/6... Step: 5900... Loss: 0.063711... Val Loss: 0.381462\n",
      "Epoch: 5/6... Step: 6000... Loss: 0.076523... Val Loss: 0.408838\n",
      "Epoch: 5/6... Step: 6100... Loss: 0.045428... Val Loss: 0.409124\n",
      "Epoch: 5/6... Step: 6200... Loss: 0.155755... Val Loss: 0.365947\n",
      "Epoch: 5/6... Step: 6300... Loss: 0.117685... Val Loss: 0.370879\n",
      "Epoch: 5/6... Step: 6400... Loss: 0.228889... Val Loss: 0.381890\n",
      "Epoch: 5/6... Step: 6500... Loss: 0.132342... Val Loss: 0.375763\n",
      "Epoch: 5/6... Step: 6600... Loss: 0.110504... Val Loss: 0.365192\n",
      "Epoch: 6/6... Step: 6700... Loss: 0.019772... Val Loss: 0.432537\n",
      "Epoch: 6/6... Step: 6800... Loss: 0.021408... Val Loss: 0.420656\n",
      "Epoch: 6/6... Step: 6900... Loss: 0.011879... Val Loss: 0.448714\n",
      "Epoch: 6/6... Step: 7000... Loss: 0.068804... Val Loss: 0.448190\n",
      "Epoch: 6/6... Step: 7100... Loss: 0.069040... Val Loss: 0.447651\n",
      "Epoch: 6/6... Step: 7200... Loss: 0.021852... Val Loss: 0.465153\n",
      "Epoch: 6/6... Step: 7300... Loss: 0.013843... Val Loss: 0.447439\n",
      "Epoch: 6/6... Step: 7400... Loss: 0.047664... Val Loss: 0.425501\n",
      "Epoch: 6/6... Step: 7500... Loss: 0.180504... Val Loss: 0.413135\n",
      "Epoch: 6/6... Step: 7600... Loss: 0.102406... Val Loss: 0.417624\n",
      "Epoch: 6/6... Step: 7700... Loss: 0.312894... Val Loss: 0.413441\n",
      "Epoch: 6/6... Step: 7800... Loss: 0.023407... Val Loss: 0.405026\n",
      "Epoch: 6/6... Step: 7900... Loss: 0.069406... Val Loss: 0.445435\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "if(not train_on_gpu):\n",
    "    raise \n",
    "epochs = 1 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity    \n",
    "    \n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "                valid_loss = np.mean(val_losses)\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            \n",
    "            # save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "                torch.save(net.state_dict(), 'model.pt')\n",
    "                valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPRVyDLNlPnN"
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pP-pc9pfbXkI",
    "outputId": "de9f8322-825b-47c6-c5ce-a2fb440ed0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.286\n",
      "Test accuracy: 0.883\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hT16EkscwwPJ"
   },
   "outputs": [],
   "source": [
    "# negative test review\n",
    "test_review_neg = 'O produto não chegou'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zolD6ECAzNIU",
    "outputId": "2cc94bfd-2ddb-41ea-8595-50b5c30650cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 7, 14]]\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def tokenize_review(test_review):\n",
    "    test_review = test_review.lower() # lowercase\n",
    "    # get rid of punctuation\n",
    "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "\n",
    "    # splitting by spaces\n",
    "    test_words = test_text.split()\n",
    "\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int.get(word) for word in test_words if vocab_to_int.get(word) != None ])\n",
    "    \n",
    "\n",
    "    return test_ints\n",
    "\n",
    "# test code and generate tokenized review\n",
    "test_ints = tokenize_review(test_review_neg)\n",
    "#test_ints.remove('')\n",
    "print(test_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B7lMpf5i3cKB",
    "outputId": "9dbcd607-2c4d-4401-baa3-504b11ad29f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  7 14]]\n"
     ]
    }
   ],
   "source": [
    "# test sequence padding\n",
    "seq_length=20\n",
    "features = pad_features(test_ints, seq_length)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eJinyjBP3i_a",
    "outputId": "79c34dee-6216-4da1-d237-90860fb905e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "# test conversion to tensor and pass into your model\n",
    "feature_tensor = torch.from_numpy(features)\n",
    "print(feature_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpHRaaEH3u4B"
   },
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=200):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # tokenize review\n",
    "    test_ints = tokenize_review(test_review)\n",
    "    \n",
    "    # pad tokenized sequence\n",
    "    seq_length=sequence_length\n",
    "    features = pad_features(test_ints, seq_length)\n",
    "    \n",
    "    # convert to tensor to pass into your model\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    \n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    # get the output from the model\n",
    "    output, h = net(feature_tensor, h)\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze()) \n",
    "    # printing output value, before rounding\n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    # print custom response\n",
    "    if(pred.item()==1):\n",
    "        print(\"Positive review detected!\")\n",
    "    else:\n",
    "        print(\"Negative review detected.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jC3b51xpOjLH"
   },
   "outputs": [],
   "source": [
    "# positive test review\n",
    "test_review_pos = 'Comecei a usar agora'\n",
    "# negative test review\n",
    "test_review_neg = 'Não posso! Estou aguardando a chegada do produto que comprei!Logo que isso aconteça, terei minha opinião formada!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "M_1LiRLPOu3l",
    "outputId": "07bda78d-69aa-48d6-a17c-c25e7aa77092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.406388\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "# call function\n",
    "seq_length=20 # good to use the length that was trained on\n",
    "\n",
    "predict(net, test_review_pos, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0H8SQT9TO2zj",
    "outputId": "a5a7a5f6-404b-4cb9-df5f-eb089bc224fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.099948\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "# call function\n",
    "seq_length=20 # good to use the length that was trained on\n",
    "\n",
    "predict(net, test_review_neg, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BjFiWgtO-Rb"
   },
   "outputs": [],
   "source": [
    "net"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
