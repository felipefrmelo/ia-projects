{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados/olist_order_reviews_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      "review_id                  100000 non-null object\n",
      "order_id                   100000 non-null object\n",
      "review_score               100000 non-null int64\n",
      "review_comment_title       11715 non-null object\n",
      "review_comment_message     41753 non-null object\n",
      "review_creation_date       100000 non-null object\n",
      "review_answer_timestamp    100000 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15197aa66ff4d0650b5434f1b46cda19</td>\n",
       "      <td>b18dcdf73be66366873cd26c5724d1dc</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-13 00:00:00</td>\n",
       "      <td>2018-04-16 00:39:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07f9bee5d1b850860defd761afa7ff16</td>\n",
       "      <td>e48aa0d2dcec3a2e87348811bcfdf22b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-16 00:00:00</td>\n",
       "      <td>2017-07-18 19:30:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7c6400515c67679fbee952a7525281ef</td>\n",
       "      <td>c31a859e34e3adac22f376954e19b39d</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-14 00:00:00</td>\n",
       "      <td>2018-08-14 21:36:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a3f6f7f6f433de0aefbb97da197c554c</td>\n",
       "      <td>9c214ac970e84273583ab523dfafd09b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-17 00:00:00</td>\n",
       "      <td>2017-05-18 12:05:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>b9bf720beb4ab3728760088589c62129</td>\n",
       "      <td>4</td>\n",
       "      <td>recomendo</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>2018-05-22 00:00:00</td>\n",
       "      <td>2018-05-23 16:45:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "5  15197aa66ff4d0650b5434f1b46cda19  b18dcdf73be66366873cd26c5724d1dc   \n",
       "6  07f9bee5d1b850860defd761afa7ff16  e48aa0d2dcec3a2e87348811bcfdf22b   \n",
       "7  7c6400515c67679fbee952a7525281ef  c31a859e34e3adac22f376954e19b39d   \n",
       "8  a3f6f7f6f433de0aefbb97da197c554c  9c214ac970e84273583ab523dfafd09b   \n",
       "9  8670d52e15e00043ae7de4c01cc2fe06  b9bf720beb4ab3728760088589c62129   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "5             1                  NaN   \n",
       "6             5                  NaN   \n",
       "7             5                  NaN   \n",
       "8             5                  NaN   \n",
       "9             4            recomendo   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "5                                                NaN  2018-04-13 00:00:00   \n",
       "6                                                NaN  2017-07-16 00:00:00   \n",
       "7                                                NaN  2018-08-14 00:00:00   \n",
       "8                                                NaN  2017-05-17 00:00:00   \n",
       "9  aparelho eficiente. no site a marca do aparelh...  2018-05-22 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  \n",
       "5     2018-04-16 00:39:37  \n",
       "6     2017-07-18 19:30:34  \n",
       "7     2018-08-14 21:36:06  \n",
       "8     2017-05-18 12:05:37  \n",
       "9     2018-05-23 16:45:47  "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.070890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.359663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_score\n",
       "count  100000.000000\n",
       "mean        4.070890\n",
       "std         1.359663\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11858</td>\n",
       "      <td>11858</td>\n",
       "      <td>1957</td>\n",
       "      <td>9179</td>\n",
       "      <td>11858</td>\n",
       "      <td>11858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3235</td>\n",
       "      <td>3235</td>\n",
       "      <td>494</td>\n",
       "      <td>2229</td>\n",
       "      <td>3235</td>\n",
       "      <td>3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8287</td>\n",
       "      <td>8287</td>\n",
       "      <td>843</td>\n",
       "      <td>3665</td>\n",
       "      <td>8287</td>\n",
       "      <td>8287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19200</td>\n",
       "      <td>19200</td>\n",
       "      <td>1743</td>\n",
       "      <td>6034</td>\n",
       "      <td>19200</td>\n",
       "      <td>19200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57420</td>\n",
       "      <td>57420</td>\n",
       "      <td>6678</td>\n",
       "      <td>20646</td>\n",
       "      <td>57420</td>\n",
       "      <td>57420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              review_id  order_id  review_comment_title  \\\n",
       "review_score                                              \n",
       "1                 11858     11858                  1957   \n",
       "2                  3235      3235                   494   \n",
       "3                  8287      8287                   843   \n",
       "4                 19200     19200                  1743   \n",
       "5                 57420     57420                  6678   \n",
       "\n",
       "              review_comment_message  review_creation_date  \\\n",
       "review_score                                                 \n",
       "1                               9179                 11858   \n",
       "2                               2229                  3235   \n",
       "3                               3665                  8287   \n",
       "4                               6034                 19200   \n",
       "5                              20646                 57420   \n",
       "\n",
       "              review_answer_timestamp  \n",
       "review_score                           \n",
       "1                               11858  \n",
       "2                                3235  \n",
       "3                                8287  \n",
       "4                               19200  \n",
       "5                               57420  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('review_score').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      NaN\n",
       "1                                                      NaN\n",
       "2                                                      NaN\n",
       "3                    Recebi bem antes do prazo estipulado.\n",
       "4        Parabéns lojas lannister adorei comprar pela I...\n",
       "5                                                      NaN\n",
       "6                                                      NaN\n",
       "7                                                      NaN\n",
       "8                                                      NaN\n",
       "9        aparelho eficiente. no site a marca do aparelh...\n",
       "10                                                     NaN\n",
       "11                                                     NaN\n",
       "12         Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "13                                                     NaN\n",
       "14                                                     NaN\n",
       "15       Vendedor confiável, produto ok e entrega antes...\n",
       "16       GOSTARIA DE SABER O QUE HOUVE, SEMPRE RECEBI E...\n",
       "17                                                     NaN\n",
       "18                                                     NaN\n",
       "19                                                 Péssimo\n",
       "20                                                     NaN\n",
       "21                                                     NaN\n",
       "22                                            Loja nota 10\n",
       "23                                                     NaN\n",
       "24                   obrigado pela atençao amim dispensada\n",
       "25                                                     NaN\n",
       "26                                                     NaN\n",
       "27       A compra foi realizada facilmente.\\r\\nA entreg...\n",
       "28                          relógio muito bonito e barato.\n",
       "29                     Não gostei ! Comprei gato por lebre\n",
       "                               ...                        \n",
       "99970                                                  NaN\n",
       "99971    Ficamos muito satisfeitos com o produto, atend...\n",
       "99972    Bom dia \\r\\nDas 6 unidades compradas só recebi...\n",
       "99973                                                  NaN\n",
       "99974                                                  NaN\n",
       "99975    Foto muito diferente principalmente a graninha...\n",
       "99976                                                  NaN\n",
       "99977    Produto original,prazo de entrega rápido.Super...\n",
       "99978    Tive um problema na entrega em que o correio c...\n",
       "99979                                                  NaN\n",
       "99980    para este produto recebi de acordo com a compr...\n",
       "99981                                                  NaN\n",
       "99982                                                  NaN\n",
       "99983    Entregou dentro do prazo. O produto chegou em ...\n",
       "99984                                                  NaN\n",
       "99985                                                  NaN\n",
       "99986                                                  NaN\n",
       "99987                                                  NaN\n",
       "99988                                                  NaN\n",
       "99989                                                  NaN\n",
       "99990    O produto não foi enviado com NF, não existe v...\n",
       "99991                                                  NaN\n",
       "99992                                                  NaN\n",
       "99993                                                  NaN\n",
       "99994                                                  NaN\n",
       "99995                                                  NaN\n",
       "99996    Excelente mochila, entrega super rápida. Super...\n",
       "99997                                                  NaN\n",
       "99998    Solicitei a compra de uma capa de retrovisor c...\n",
       "99999    meu produto chegou e ja tenho que devolver, po...\n",
       "Name: review_comment_message, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_comment_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['review_score','review_comment_message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felli\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels , reviews = df1['review_score'].values,df1['review_comment_message'].apply(str.lower).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5, 3, 4, 4, 1, 3, 2, 5, 4, 5, 5, 5, 1, 2, 5, 1, 1, 2, 3, 5, 3, 5, 1, 5,\n",
       "         5, 5, 1, 4, 1, 5, 1, 5, 5, 1, 4, 1, 5, 4, 4, 5, 5, 5, 5, 1, 5, 4, 5, 5,\n",
       "         1, 5]), array(['recebi bem antes do prazo estipulado.',\n",
       "        'parabéns lojas lannister adorei comprar pela internet seguro e prático parabéns a todos feliz páscoa',\n",
       "        'aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que é o mesmo aparelho',\n",
       "        ...,\n",
       "        'excelente mochila, entrega super rápida. super recomendo essa loja!',\n",
       "        'solicitei a compra de uma capa de retrovisor celta/prisma/meriva - preta - lado esquerdo, mas chegou para mim uma capa do lado direito de outro modelo de carro.\\r\\nestou decepcionado! fico no aguardo!',\n",
       "        'meu produto chegou e ja tenho que devolver, pois está com defeito , não segurar carga'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels,reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# get rid of punctuation\n",
    "reviews_split= []\n",
    "for review in reviews:\n",
    "    reviews_split.append(''.join([c for c in review if c not in punctuation]).replace('\\r\\n',' '))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split by new lines and spaces\n",
    "#reviews_split = all_text.split('\\n')\n",
    "all_text = ' '.join(reviews_split)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recebi',\n",
       " 'bem',\n",
       " 'antes',\n",
       " 'do',\n",
       " 'prazo',\n",
       " 'estipulado',\n",
       " 'parabéns',\n",
       " 'lojas',\n",
       " 'lannister',\n",
       " 'adorei',\n",
       " 'comprar',\n",
       " 'pela',\n",
       " 'internet',\n",
       " 'seguro',\n",
       " 'e',\n",
       " 'prático',\n",
       " 'parabéns',\n",
       " 'a',\n",
       " 'todos',\n",
       " 'feliz',\n",
       " 'páscoa',\n",
       " 'aparelho',\n",
       " 'eficiente',\n",
       " 'no',\n",
       " 'site',\n",
       " 'a',\n",
       " 'marca',\n",
       " 'do',\n",
       " 'aparelho',\n",
       " 'esta']"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recebi bem antes do prazo estipulado',\n",
       " 'parabéns lojas lannister adorei comprar pela internet seguro e prático parabéns a todos feliz páscoa',\n",
       " 'aparelho eficiente no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nomeatualizar com a marca correta uma vez que é o mesmo aparelho',\n",
       " 'mas um pouco travandopelo valor ta boa ',\n",
       " 'vendedor confiável produto ok e entrega antes do prazo']"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_split[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the words\n",
    "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our reviews into integers so they can be passed into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "## use the dict to tokenize each review in reviews_split\n",
    "## store the tokenized reviews in reviews_ints\n",
    "reviews_ints = []\n",
    "for review in reviews_split:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  20190\n",
      "\n",
      "Tokenized review: \n",
      " [[15, 28, 13, 6, 9, 232]]\n"
     ]
    }
   ],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "print()\n",
    "\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', reviews_ints[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_string = { ii: word for word, ii  in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 4, ..., 5, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 132\n",
      "Maximum review length: 45\n"
     ]
    }
   ],
   "source": [
    "# outlier review stats\n",
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  41753\n",
      "Number of reviews after removing outliers:  41621\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
    "\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "\n",
    "# remove 0-length reviews and their labels\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "\n",
    "print('Number of reviews after removing outliers: ', len(reviews_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    15   28   13    6    9  232]\n",
      " [   0    0    0    0    0   80  156   64   94   75  106  446  657    3\n",
      "   628   80    4  122  392 5772]\n",
      " [ 433  358   16   62    4  376    6  433  131 2429   44 8210    3   85\n",
      "   185  131   12  100 8211   12]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0   29\n",
      "    20  140 8212  161  762   59]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  130  388    2\n",
      "    97    3   11   13    6    9]\n",
      " [   0    0    0    0    0    0  186    5  174    1    8  289   70   15\n",
      "     3  167   37   72   48 8213]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  343]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   34   91  192]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  147  106 3458 8214 5773]\n",
      " [   4   37   17  498 2430    4   11   17  809   10   13    6    9  696\n",
      "     1    2   57 2258    4   67]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  141   10  150    3  587]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     7   41   30 2608   49 3459]\n",
      " [  70  162  106  446    3    4   11 1942   13    6    9  208    8  499\n",
      "    67    1    9  889   16  201]\n",
      " [   0    0    0   15  228    1    8  168   51  326 1153    5  345 1943\n",
      "  2259   29  131   14   16    9]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   21]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0   10   59]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0 1036  844\n",
      "  1850   34   47  879    3  388]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    95    5  185    1   38   54]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   10   19   10 2826]\n",
      " [   0    0    0    0    0    0    0    0    0    0  108  130   14  195\n",
      "    13    6    9   94    1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   504    5   37 1154    3  358]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0 8215\n",
      "   104 3096   65   18    5 8216]\n",
      " [   0    0    0    0    0    0   15  169   98  394 5774 8217 3097  296\n",
      "   394 1257   26 1258 1851 4612]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   59]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0  600  118]\n",
      " [   0    0    0    0    0    0    0  365   36   44 1605  209    4   11\n",
      "   498   13    6    9   40  103]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   109  115  118   10 1718   94]\n",
      " [  79   34   26 1782 8218   60   28 1053    3    5   32   42    1  335\n",
      "     6  112    8   17  588 8219]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   21    1  130]\n",
      " [   1    2    7   14   16    9  232    3 2609  823  279 8220    4 1492\n",
      "     5 3921    6   38  521 4613]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 20\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(33296, 20) \n",
      "Validation set: \t(4162, 20) \n",
      "Test set: \t\t(4163, 20)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     6,     9,   232],\n",
       "       [    0,     0,     0, ...,   122,   392,  5772],\n",
       "       [  433,   358,    16, ...,   100,  8211,    12],\n",
       "       ...,\n",
       "       [    1,   396,   298, ...,   100,  3392,  5262],\n",
       "       [    0,     0,     0, ...,    71,  5040, 17890],\n",
       "       [    0,     0,     0, ...,   863,   106,    34]])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 10\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([10, 20])\n",
      "Sample input: \n",
      " tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    2,   10,   19,   52,    6,  378],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,   33, 6825,    8,  298,\n",
      "            1,   54,  317,   22,   24,   20,   42,   58],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,   19,    2],\n",
      "        [   2,  150,   16,  620,    5, 1034,   32,    7, 4783,   85,  157,   44,\n",
      "         2884,    5,   32,   12,  681, 1917, 4384,   27],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,   15,   50,   60,   52,    6,    9,  147],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,  109,    1,  330,   10,  118],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    4,   11,   87,\n",
      "           60,   17,   10, 5334,    3,  275,   23,   93],\n",
      "        [   0,    0,    0,    0,   43,    1,  135,    7,   15,    1,    2,    7,\n",
      "         1150,   24,  110,   26,  435,    1,  104,  289],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,  250,   15,   77],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   15,    1,\n",
      "          677, 3169,   38,   54,   17,    1,  677, 7688]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([10])\n",
      "Sample label: \n",
      " tensor([5, 3, 4, 1, 4, 4, 3, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tradutor(review_int):\n",
    "    \n",
    "    texto=[vocab_to_string[c] if c != 0 else '' for c in review_int ]\n",
    "    \n",
    "    texto = ' '.join(texto)\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(20191, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 5\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUIntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-382-8a582a3267a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# get the output from the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# calculate the loss and perform backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-368-b99cefc1dc61>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# embeddings and lstm_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    108\u001b[0m         return F.embedding(\n\u001b[0;32m    109\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUIntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "\n",
    "# training params\n",
    "\n",
    "epochs = 1 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 20])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
